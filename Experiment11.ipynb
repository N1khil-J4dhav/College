{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPt6GPxVqjkjsu8O2Rm+Nd4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/N1khil-J4dhav/College/blob/main/Experiment11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37yDtRGjaanV",
        "outputId": "8a8d93d7-956e-4348-cf94-0b50bd5e6369",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully, including RandomForestRegressor.\n",
            "\n",
            "Dataset loaded and prepared with dummy categorical features and NaNs.\n",
            "\n",
            "Full Random Forest Pipeline created.\n",
            "Data split into Training (16512 samples) and Test (4128 samples).\n",
            "\n",
            "Starting model training...\n",
            "Model training complete.\n",
            "\n",
            "--- Model Evaluation (Random Forest) ---\n",
            "Bagging Ensemble Technique: Random Forest Regressor\n",
            "Mean Squared Error (MSE): 0.2570\n",
            "Root Mean Squared Error (RMSE): 0.5069\n",
            "R-squared (Variance Explained): 0.8039\n",
            "------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor # The key algorithm for this experiment\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "print(\"Libraries imported successfully, including RandomForestRegressor.\")\n",
        "\n",
        "# Step 2: Load the dataset (California Housing)\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "df = housing.frame\n",
        "df['MedHouseVal'] = housing.target\n",
        "\n",
        "# --- Prepare data for Preprocessing Pipeline ---\n",
        "# Manually add the categorical column and introduce NaNs for demonstration purposes,\n",
        "# replicating the setup from the previous experiment.\n",
        "np.random.seed(42)\n",
        "df['ocean_proximity'] = np.random.choice(['<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'NEAR BAY', 'ISLAND'], size=len(df))\n",
        "missing_indices = np.random.choice(df.index, size=200, replace=False)\n",
        "df.loc[missing_indices, 'AveBedrms'] = np.nan\n",
        "\n",
        "print(\"\\nDataset loaded and prepared with dummy categorical features and NaNs.\")\n",
        "\n",
        "# Step 3: Define Features and Target\n",
        "X = df.drop('MedHouseVal', axis=1)\n",
        "y = df['MedHouseVal']\n",
        "\n",
        "# Step 4: Define Column Types\n",
        "numeric_features = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
        "categorical_features = ['ocean_proximity']\n",
        "\n",
        "# Step 5: Create Preprocessing Pipelines\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Step 6: Combine all Preprocessing Steps using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Step 7: Create the Full ML Pipeline (Preprocessing + Model)\n",
        "# This is the \"Bagging Ensemble\" step: the Random Forest Regressor\n",
        "rf_model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(\n",
        "        n_estimators=100,      # Number of decision trees (base estimators)\n",
        "        max_features='sqrt',   # Number of features to consider when looking for the best split\n",
        "        random_state=42,\n",
        "        n_jobs=-1              # Use all available cores for faster training\n",
        "    ))\n",
        "])\n",
        "\n",
        "print(\"\\nFull Random Forest Pipeline created.\")\n",
        "\n",
        "# Step 8: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"Data split into Training ({X_train.shape[0]} samples) and Test ({X_test.shape[0]} samples).\")\n",
        "\n",
        "# Step 9: Train the Random Forest Model\n",
        "# The pipeline handles both preprocessing (fit_transform) and model training (fit) automatically\n",
        "print(\"\\nStarting model training...\")\n",
        "rf_model.fit(X_train, y_train)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# Step 10: Make predictions on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Step 11: Evaluate the Model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'\\n--- Model Evaluation (Random Forest) ---')\n",
        "print(f'Bagging Ensemble Technique: Random Forest Regressor')\n",
        "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
        "print(f'R-squared (Variance Explained): {r2:.4f}')\n",
        "print(f'------------------------------------------')"
      ]
    }
  ]
}