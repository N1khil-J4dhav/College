{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObtZ8KKK+rB5FkM/4dDOKj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/N1khil-J4dhav/College/blob/main/Experiment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INYk474lZNne",
        "outputId": "79dee938-c852-4661-87de-0b763dd83a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully.\n",
            "\n",
            "--- Dataset Head (with artificial NaNs in AveBedrms) ---\n",
            "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
            "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
            "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
            "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
            "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
            "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
            "\n",
            "   Longitude  MedHouseVal ocean_proximity  \n",
            "0    -122.23        4.526        NEAR BAY  \n",
            "1    -122.22        3.585          ISLAND  \n",
            "2    -122.24        3.521      NEAR OCEAN  \n",
            "3    -122.25        3.413          ISLAND  \n",
            "4    -122.25        3.422          ISLAND  \n",
            "---------------------------------------------------------\n",
            "Total rows with missing values before processing: 200\n",
            "\n",
            "Numeric features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
            "Categorical features: ['ocean_proximity']\n",
            "\n",
            "ColumnTransformer (Preprocessing Pipeline) created.\n",
            "\n",
            "--- Preprocessed Data (X_processed_df.head()) ---\n",
            "     MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
            "0  2.344766  0.982143  0.628559  -0.154620   -0.974429 -0.049597  1.052548   \n",
            "1  2.332238 -0.607019  0.327041  -0.264244    0.861439 -0.092512  1.043185   \n",
            "2  1.782699  1.856182  1.155620  -0.049834   -0.820777 -0.025843  1.038503   \n",
            "3  0.932968  1.856182  0.156966  -0.050651   -0.766028 -0.050329  1.038503   \n",
            "4 -0.012881  1.856182  0.344711  -0.033717   -0.759847 -0.085616  1.038503   \n",
            "\n",
            "   Longitude  ocean_proximity_<1H OCEAN  ocean_proximity_INLAND  \\\n",
            "0  -1.327835                        0.0                     0.0   \n",
            "1  -1.322844                        0.0                     0.0   \n",
            "2  -1.332827                        0.0                     0.0   \n",
            "3  -1.337818                        0.0                     0.0   \n",
            "4  -1.337818                        0.0                     0.0   \n",
            "\n",
            "   ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \\\n",
            "0                     0.0                       1.0   \n",
            "1                     1.0                       0.0   \n",
            "2                     0.0                       0.0   \n",
            "3                     1.0                       0.0   \n",
            "4                     1.0                       0.0   \n",
            "\n",
            "   ocean_proximity_NEAR OCEAN  \n",
            "0                         0.0  \n",
            "1                         0.0  \n",
            "2                         1.0  \n",
            "3                         0.0  \n",
            "4                         0.0  \n",
            "\n",
            "Original number of features: 9\n",
            "New number of features (after One-Hot Encoding): 13\n",
            "Shape of Preprocessed Data: (20640, 13)\n",
            "-------------------------------------------------\n",
            "\n",
            "Successfully completed data preprocessing (Expt 02).\n",
            "The data is now scaled, missing values are imputed, and categorical features are encoded.\n",
            "\n",
            "Processed Training Set Shape (for ML): (16512, 13)\n",
            "Processed Testing Set Shape (for ML): (4128, 13)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing # Built-in dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer # For handling missing values\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder # For scaling and encoding\n",
        "from sklearn.compose import ColumnTransformer # For applying different transforms to different columns\n",
        "from sklearn.pipeline import Pipeline # To chain the steps\n",
        "\n",
        "print(\"Libraries imported successfully.\")\n",
        "\n",
        "# Step 2: Load the dataset (California Housing)\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "df = housing.frame\n",
        "\n",
        "# The target variable is 'MedHouseVal' (Median House Value)\n",
        "df['MedHouseVal'] = housing.target\n",
        "\n",
        "# --- FIX: Manually add the missing 'ocean_proximity' categorical column with dummy data ---\n",
        "# The standard fetch_california_housing often excludes this feature.\n",
        "# We add it here to ensure the OneHotEncoder step in the pipeline is demonstrated successfully.\n",
        "np.random.seed(42)\n",
        "df['ocean_proximity'] = np.random.choice(['<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'NEAR BAY', 'ISLAND'], size=len(df))\n",
        "# ---------------------------------------------------------------------------------------\n",
        "\n",
        "# Note: The original dataset is clean, but we will artificially introduce\n",
        "# some missing values in 'AveBedrms' to demonstrate the Imputer.\n",
        "np.random.seed(42)\n",
        "missing_indices = np.random.choice(df.index, size=200, replace=False)\n",
        "df.loc[missing_indices, 'AveBedrms'] = np.nan\n",
        "\n",
        "# The 'ocean_proximity' column is categorical, requiring encoding.\n",
        "print(\"\\n--- Dataset Head (with artificial NaNs in AveBedrms) ---\")\n",
        "print(df.head())\n",
        "print(\"---------------------------------------------------------\")\n",
        "print(f\"Total rows with missing values before processing: {df.isnull().any(axis=1).sum()}\")\n",
        "\n",
        "\n",
        "# Step 3: Define Features and Target\n",
        "X = df.drop('MedHouseVal', axis=1) # All features\n",
        "y = df['MedHouseVal'] # Target\n",
        "\n",
        "# Step 4: Define Column Types\n",
        "# We explicitly list the features now that 'ocean_proximity' has been added,\n",
        "# instead of relying on brittle column indexing.\n",
        "numeric_features = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
        "categorical_features = ['ocean_proximity']\n",
        "\n",
        "print(f\"\\nNumeric features: {numeric_features}\")\n",
        "print(f\"Categorical features: {categorical_features}\")\n",
        "\n",
        "\n",
        "# Step 5: Create Preprocessing Pipelines for Numeric and Categorical Data\n",
        "\n",
        "# 5.1 Pipeline for Numeric features (Imputation and Scaling)\n",
        "# A) Imputer: Fills missing values with the mean of the column\n",
        "# B) Scaler: Standardizes features (mean=0, variance=1)\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# 5.2 Pipeline for Categorical features (One-Hot Encoding)\n",
        "# One-Hot Encoding turns categories into binary (0 or 1) columns.\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore')) # 'ignore' handles new categories not seen during training\n",
        "])\n",
        "\n",
        "# Step 6: Combine all Preprocessing Steps using ColumnTransformer\n",
        "# This is the \"brain\" that applies the right transformer to the right column.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough' # Keep any columns not specified (if any)\n",
        ")\n",
        "\n",
        "print(\"\\nColumnTransformer (Preprocessing Pipeline) created.\")\n",
        "\n",
        "\n",
        "# Step 7: Apply the Preprocessor to the Data\n",
        "# The preprocessor is trained and applied in one step\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "\n",
        "# Step 8: Convert the result back to a DataFrame and Display\n",
        "# Get feature names after one-hot encoding\n",
        "# The OneHotEncoder output feature names will include the original feature name as a prefix\n",
        "cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
        "feature_names_out = numeric_features + list(cat_feature_names)\n",
        "\n",
        "X_processed_df = pd.DataFrame(X_processed, columns=feature_names_out)\n",
        "\n",
        "\n",
        "print(\"\\n--- Preprocessed Data (X_processed_df.head()) ---\")\n",
        "print(X_processed_df.head())\n",
        "print(f\"\\nOriginal number of features: {X.shape[1]}\")\n",
        "print(f\"New number of features (after One-Hot Encoding): {X_processed_df.shape[1]}\")\n",
        "print(f\"Shape of Preprocessed Data: {X_processed_df.shape}\")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "print(\"\\nSuccessfully completed data preprocessing (Expt 02).\")\n",
        "print(\"The data is now scaled, missing values are imputed, and categorical features are encoded.\")\n",
        "\n",
        "# Optional: Split the processed data for training a model (as the next logical step)\n",
        "X_train_proc, X_test_proc, y_train_proc, y_test_proc = train_test_split(\n",
        "    X_processed, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nProcessed Training Set Shape (for ML): {X_train_proc.shape}\")\n",
        "print(f\"Processed Testing Set Shape (for ML): {X_test_proc.shape}\")"
      ]
    }
  ]
}